{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_tuning_booking_price_to_maximize_expected_revenue.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patelatharva/Analysis_of_Airbnb_property_listings_dataset/blob/master/colab_tuning_booking_price_to_maximize_expected_revenue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB67i5sRvR3b",
        "colab_type": "text"
      },
      "source": [
        "# A predictive analysis of how a booking company tune its prices of individual properties to maximize expected revenue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jmbLKuzJyFkm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e56fd9a6-6a47-45a6-b815-9c966e8432a7"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import seaborn as sns\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import math\n",
        "from sklearn.base import clone\n",
        "!pip install -q scikit-optimize\n",
        "from skopt import gp_minimize\n",
        "!pip install -q hyperopt\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from hyperopt import space_eval\n",
        "!pip install -q keras\n",
        "!pip install -q tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "!pip install -q h5py\n",
        "from keras.models import load_model\n",
        "import pprint\n",
        "import random\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▍                           | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cu9Gc4QLyFk1"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EoAef2Tqz406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cd536262-3dac-4061-f4cf-5ae89326006c"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CfFaiZyK0WAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "224b1821-9fa0-4b7d-a37c-0ada9a671dc4"
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/Data Scientist/airbnb/data/boston\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calendar.csv  nn_best_model_1.h5     reviews.csv   X_train_sample.csv\n",
            "dtc_best.pkl  nn_best_model_cv.h5    xgb_best.pkl  y_test.csv\n",
            "gb_best.pkl   nn_best_model.h5\t     X_test.csv    y_train.csv\n",
            "listings.csv  nn_best_model_temp.h5  X_train.csv   y_train_sample.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-N4NAgE0sPQ",
        "colab": {}
      },
      "source": [
        "project_dir = \"/content/gdrive/My Drive/Data Scientist/airbnb\"\n",
        "data_dir = project_dir + \"/data/boston\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zLzWyzWhsdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# project_dir = \".\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_Mb4_9pyFk2",
        "colab": {}
      },
      "source": [
        "calendar = pd.read_csv(data_dir + \"/calendar.csv\")\n",
        "reviews = pd.read_csv(data_dir + \"/reviews.csv\")\n",
        "listings = pd.read_csv(data_dir + \"/listings.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3QkIcOZ6Fl_R",
        "outputId": "c7dbeb97-6fe6-44ac-cfce-fa6899d1da8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "listings[\"id\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hlXy-voYyFk5"
      },
      "source": [
        "### Transforming 'price' from string to numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XKSmbEjyFk6",
        "outputId": "aa8953eb-981c-43dd-ffb1-4a398b6a530b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\"\"\"\n",
        "    Converts price in the string format like \"$1,125.00\" into numeric value 1125.00\n",
        "    INPUT:\n",
        "    - string price in string format\n",
        "    OUTPUT:\n",
        "    - float value corresponding to the price or None if the input is not parseable to float\n",
        "\"\"\"\n",
        "def str_to_num (string):\n",
        "    if string is not None:\n",
        "        if type(string) is str and string.startswith('$'):\n",
        "            return float(string.replace('$', '').replace(',', ''))\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "listings_cleaned = pd.concat([listings.drop('price', axis=1), listings[\"price\"].apply(str_to_num)], axis=1)\n",
        "listings_cleaned['price'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    250.0\n",
              "1     65.0\n",
              "2     65.0\n",
              "3     75.0\n",
              "4     79.0\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-oBi3pYyFk9",
        "outputId": "b458fa36-f182-4575-88f6-684877c1fdb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "calendar_cleaned = pd.concat([calendar.drop('price', axis=1), calendar[\"price\"].apply(str_to_num)], axis=1)\n",
        "calendar_cleaned['price'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   NaN\n",
              "1   NaN\n",
              "2   NaN\n",
              "3   NaN\n",
              "4   NaN\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C0S7xcx6yFlA"
      },
      "source": [
        "### Converting 'avilable' field from string to binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gj4ErNR1yFlB",
        "outputId": "01427eeb-a77c-424f-9610-07d316faa95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "calendar_cleaned['available'] = calendar_cleaned['available'] == 't'\n",
        "calendar_cleaned['available'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1    False\n",
              "2    False\n",
              "3    False\n",
              "4    False\n",
              "Name: available, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2CRwPuIqyFlE"
      },
      "source": [
        "### Converting 'date' from string to datetime format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1AzGFXl8yFlF",
        "colab": {}
      },
      "source": [
        "calendar_cleaned[\"date\"] = pd.to_datetime(calendar_cleaned[\"date\"], format=\"%Y-%m-%d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ckk-R1R3yFlJ"
      },
      "source": [
        "### Converting location field from numeric to categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TuPJ39X1yFlK",
        "colab": {}
      },
      "source": [
        "listings_cleaned[\"location_categorical\"] = listings_cleaned.apply(lambda row: str((format(row.latitude, '.2f'), format(row.longitude, '.2f'))), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k8o4rtMQyFlN",
        "outputId": "04fed338-6fbc-41cc-89a6-c33c801c296d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "listings_cleaned.location_categorical.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ('42.28', '-71.13')\n",
              "1    ('42.29', '-71.13')\n",
              "2    ('42.29', '-71.14')\n",
              "3    ('42.28', '-71.12')\n",
              "4    ('42.28', '-71.14')\n",
              "Name: location_categorical, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ImOYNZ59yFlP"
      },
      "source": [
        "### Converting 'amenities' field containing list into separate categorical columns for each amenity in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7L1sEyWwyFlQ",
        "outputId": "df4886ca-1263-41b1-c144-9456daa2f0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "list(map(lambda amenity : amenity.replace(\"\\\"\",\"\").replace(\"{\",\"\").replace(\"}\", \"\"), listings_cleaned.amenities.iloc[0].split(\",\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TV',\n",
              " 'Wireless Internet',\n",
              " 'Kitchen',\n",
              " 'Free Parking on Premises',\n",
              " 'Pets live on this property',\n",
              " 'Dog(s)',\n",
              " 'Heating',\n",
              " 'Family/Kid Friendly',\n",
              " 'Washer',\n",
              " 'Dryer',\n",
              " 'Smoke Detector',\n",
              " 'Fire Extinguisher',\n",
              " 'Essentials',\n",
              " 'Shampoo',\n",
              " 'Laptop Friendly Workspace']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "it7hiVFtyFlT",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Separates the string value of `amenities` attribute in the row, into a list of individual amenities.\n",
        "    \n",
        "    INPUT:\n",
        "    - row : from dataset having amenities attribute\n",
        "    OUTPUT:    \n",
        "    - list of amenities derived from the value of `amenities` attribute in row\n",
        "\"\"\"\n",
        "def separate_amenities(row):\n",
        "    amenities = row.amenities\n",
        "    list_to_return = []\n",
        "    if (amenities is not None and type(amenities) == str):            \n",
        "        list_to_return = list(map(lambda amenity : amenity.replace(\"\\\"\",\"\").replace(\"{\",\"\").replace(\"}\", \"\"), amenities.split(\",\")))\n",
        "    if '' in list_to_return:\n",
        "        list_to_return.remove('')\n",
        "    return list_to_return\n",
        "listings_cleaned[\"amenities_list\"] = listings_cleaned.apply(separate_amenities, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHE5MnhryFlV",
        "outputId": "928f3789-9dba-40ab-d26e-8fd794645aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "possible_amenities = listings_cleaned['amenities_list'].apply(pd.Series).stack().unique()\n",
        "possible_amenities"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['TV', 'Wireless Internet', 'Kitchen', 'Free Parking on Premises',\n",
              "       'Pets live on this property', 'Dog(s)', 'Heating',\n",
              "       'Family/Kid Friendly', 'Washer', 'Dryer', 'Smoke Detector',\n",
              "       'Fire Extinguisher', 'Essentials', 'Shampoo',\n",
              "       'Laptop Friendly Workspace', 'Internet', 'Air Conditioning',\n",
              "       'Pets Allowed', 'Carbon Monoxide Detector', 'Lock on Bedroom Door',\n",
              "       'Hangers', 'Hair Dryer', 'Iron', 'Cable TV', 'First Aid Kit',\n",
              "       'Safety Card', 'translation missing: en.hosting_amenity_49',\n",
              "       'translation missing: en.hosting_amenity_50', 'Gym', 'Breakfast',\n",
              "       'Indoor Fireplace', 'Cat(s)', '24-Hour Check-in', 'Hot Tub',\n",
              "       'Buzzer/Wireless Intercom', 'Other pet(s)', 'Washer / Dryer',\n",
              "       'Smoking Allowed', 'Suitable for Events', 'Wheelchair Accessible',\n",
              "       'Elevator in Building', 'Pool', 'Doorman',\n",
              "       'Paid Parking Off Premises', 'Free Parking on Street'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXSkJj4YyFlZ",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Assigns new boolean attribute to the row based on the presence of that amenity in the list.\n",
        "    Returns updated row with additional attributes corresponding to the amenities added to it.\n",
        "    \n",
        "    INPUT:\n",
        "    - row containing attributes related to the property, including `amenities_list`\n",
        "    OUTPUT:\n",
        "    - row containing newly added boolean attributes indicating the presence of each possible type of amenity in the property\n",
        "\"\"\"\n",
        "def add_amenities_columns (row):\n",
        "    amenities = set(row.amenities_list)\n",
        "    for possible_amenity in possible_amenities:\n",
        "        row[\"amenity_\" + possible_amenity] = possible_amenity in amenities\n",
        "    return row\n",
        "\n",
        "listings_cleaned = listings_cleaned.apply(add_amenities_columns, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjrJ8WFnyFlc"
      },
      "source": [
        "### Identifying the activation date for each property listing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iQ1UfXr4yFlc",
        "outputId": "1b39ba3d-a980-46a4-f74a-bdf0cc8ee664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "df = calendar_cleaned\n",
        "df = df.groupby('listing_id', group_keys=False)\\\n",
        "    .apply(lambda x: x[x.available.ne(x.available.shift())])\\\n",
        "    .reset_index(drop=True)\n",
        "df.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>listing_id</th>\n",
              "      <th>date</th>\n",
              "      <th>available</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3353</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>True</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3353</td>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3353</td>\n",
              "      <td>2017-08-18</td>\n",
              "      <td>True</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3353</td>\n",
              "      <td>2016-10-12</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5506</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-10-10</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-10-03</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-30</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-28</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-25</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-22</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-21</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-19</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-18</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-15</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-12</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5506</td>\n",
              "      <td>2016-09-08</td>\n",
              "      <td>True</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6695</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>True</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6695</td>\n",
              "      <td>2016-10-24</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6695</td>\n",
              "      <td>2016-10-19</td>\n",
              "      <td>True</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    listing_id       date  available  price\n",
              "0         3353 2017-09-05       True   36.0\n",
              "1         3353 2016-12-30      False    NaN\n",
              "2         3353 2017-08-18       True   36.0\n",
              "3         3353 2016-10-12      False    NaN\n",
              "4         5506 2017-09-05       True  145.0\n",
              "5         5506 2016-10-10      False    NaN\n",
              "6         5506 2016-10-03       True  145.0\n",
              "7         5506 2016-09-30      False    NaN\n",
              "8         5506 2016-09-28       True  145.0\n",
              "9         5506 2016-09-25      False    NaN\n",
              "10        5506 2016-09-22       True  145.0\n",
              "11        5506 2016-09-21      False    NaN\n",
              "12        5506 2016-09-19       True  145.0\n",
              "13        5506 2016-09-18      False    NaN\n",
              "14        5506 2016-09-15       True  145.0\n",
              "15        5506 2016-09-12      False    NaN\n",
              "16        5506 2016-09-08       True  145.0\n",
              "17        6695 2017-09-05       True  195.0\n",
              "18        6695 2016-10-24      False    NaN\n",
              "19        6695 2016-10-19       True  195.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BIrFIUkyFlf",
        "colab": {}
      },
      "source": [
        "listing_activation_dates = df[df.available == True].groupby(\"listing_id\")[[\"listing_id\",\"date\"]].min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pX3yGGkdyFli",
        "outputId": "0aecd336-de1e-4869-ed14-52c273ab2e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "listing_activation_dates.sort_values(by=[\"date\"]).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>listing_id</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>listing_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>530983</th>\n",
              "      <td>530983</td>\n",
              "      <td>2016-09-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815639</th>\n",
              "      <td>815639</td>\n",
              "      <td>2016-09-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12726343</th>\n",
              "      <td>12726343</td>\n",
              "      <td>2016-09-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2776391</th>\n",
              "      <td>2776391</td>\n",
              "      <td>2016-09-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10524612</th>\n",
              "      <td>10524612</td>\n",
              "      <td>2016-09-06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            listing_id       date\n",
              "listing_id                       \n",
              "530983          530983 2016-09-06\n",
              "815639          815639 2016-09-06\n",
              "12726343      12726343 2016-09-06\n",
              "2776391        2776391 2016-09-06\n",
              "10524612      10524612 2016-09-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ft6E_fCEyFls"
      },
      "source": [
        "### Only retaining entries in calendar for each property after its activation date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9t9Cw9xVyFlt",
        "colab": {}
      },
      "source": [
        "cal_by_listing_groups = calendar_cleaned.groupby([\"listing_id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Q3DS-JHyFly",
        "outputId": "32d7d293-39c3-4809-c2e0-fe35c728608f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cal_by_listing_groups.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>listing_id</th>\n",
              "      <th>date</th>\n",
              "      <th>available</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12147973</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12147973</td>\n",
              "      <td>2017-09-04</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12147973</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12147973</td>\n",
              "      <td>2017-09-02</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12147973</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>3075044</td>\n",
              "      <td>2017-08-22</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>3075044</td>\n",
              "      <td>2017-08-21</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>3075044</td>\n",
              "      <td>2017-08-20</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>3075044</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>True</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>3075044</td>\n",
              "      <td>2017-08-18</td>\n",
              "      <td>True</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>6976</td>\n",
              "      <td>2017-05-12</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>6976</td>\n",
              "      <td>2017-05-11</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>6976</td>\n",
              "      <td>2017-05-10</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>6976</td>\n",
              "      <td>2017-05-09</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>6976</td>\n",
              "      <td>2017-05-08</td>\n",
              "      <td>True</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>1436513</td>\n",
              "      <td>2017-05-10</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>1436513</td>\n",
              "      <td>2017-05-09</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>1436513</td>\n",
              "      <td>2017-05-08</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1098</th>\n",
              "      <td>1436513</td>\n",
              "      <td>2017-05-07</td>\n",
              "      <td>True</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>1436513</td>\n",
              "      <td>2017-05-06</td>\n",
              "      <td>True</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>7651065</td>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>True</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>7651065</td>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>True</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1462</th>\n",
              "      <td>7651065</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>True</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>7651065</td>\n",
              "      <td>2017-06-18</td>\n",
              "      <td>True</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1464</th>\n",
              "      <td>7651065</td>\n",
              "      <td>2017-06-17</td>\n",
              "      <td>True</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1825</th>\n",
              "      <td>12386020</td>\n",
              "      <td>2017-04-25</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>12386020</td>\n",
              "      <td>2017-04-24</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>12386020</td>\n",
              "      <td>2017-04-23</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>12386020</td>\n",
              "      <td>2017-04-22</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>12386020</td>\n",
              "      <td>2017-04-21</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306700</th>\n",
              "      <td>14852179</td>\n",
              "      <td>2017-08-20</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306701</th>\n",
              "      <td>14852179</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306702</th>\n",
              "      <td>14852179</td>\n",
              "      <td>2017-08-18</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306703</th>\n",
              "      <td>14852179</td>\n",
              "      <td>2017-08-17</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306704</th>\n",
              "      <td>14852179</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307065</th>\n",
              "      <td>8373729</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>True</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307066</th>\n",
              "      <td>8373729</td>\n",
              "      <td>2017-05-17</td>\n",
              "      <td>True</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307067</th>\n",
              "      <td>8373729</td>\n",
              "      <td>2017-05-16</td>\n",
              "      <td>True</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307068</th>\n",
              "      <td>8373729</td>\n",
              "      <td>2017-05-15</td>\n",
              "      <td>True</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307069</th>\n",
              "      <td>8373729</td>\n",
              "      <td>2017-05-14</td>\n",
              "      <td>True</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307430</th>\n",
              "      <td>14844274</td>\n",
              "      <td>2017-06-22</td>\n",
              "      <td>True</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307431</th>\n",
              "      <td>14844274</td>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>True</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307432</th>\n",
              "      <td>14844274</td>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>True</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307433</th>\n",
              "      <td>14844274</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>True</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307434</th>\n",
              "      <td>14844274</td>\n",
              "      <td>2017-06-18</td>\n",
              "      <td>True</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307795</th>\n",
              "      <td>14585486</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307796</th>\n",
              "      <td>14585486</td>\n",
              "      <td>2017-09-04</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307797</th>\n",
              "      <td>14585486</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307798</th>\n",
              "      <td>14585486</td>\n",
              "      <td>2017-09-02</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307799</th>\n",
              "      <td>14585486</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308160</th>\n",
              "      <td>14603878</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>True</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308161</th>\n",
              "      <td>14603878</td>\n",
              "      <td>2017-09-04</td>\n",
              "      <td>True</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308162</th>\n",
              "      <td>14603878</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>True</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308163</th>\n",
              "      <td>14603878</td>\n",
              "      <td>2017-09-02</td>\n",
              "      <td>True</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308164</th>\n",
              "      <td>14603878</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>True</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308525</th>\n",
              "      <td>14504422</td>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308526</th>\n",
              "      <td>14504422</td>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308527</th>\n",
              "      <td>14504422</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308528</th>\n",
              "      <td>14504422</td>\n",
              "      <td>2017-06-18</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308529</th>\n",
              "      <td>14504422</td>\n",
              "      <td>2017-06-17</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17925 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         listing_id       date  available  price\n",
              "0          12147973 2017-09-05      False    NaN\n",
              "1          12147973 2017-09-04      False    NaN\n",
              "2          12147973 2017-09-03      False    NaN\n",
              "3          12147973 2017-09-02      False    NaN\n",
              "4          12147973 2017-09-01      False    NaN\n",
              "365         3075044 2017-08-22       True   65.0\n",
              "366         3075044 2017-08-21       True   65.0\n",
              "367         3075044 2017-08-20       True   65.0\n",
              "368         3075044 2017-08-19       True   75.0\n",
              "369         3075044 2017-08-18       True   75.0\n",
              "730            6976 2017-05-12       True   65.0\n",
              "731            6976 2017-05-11       True   65.0\n",
              "732            6976 2017-05-10       True   65.0\n",
              "733            6976 2017-05-09       True   65.0\n",
              "734            6976 2017-05-08       True   65.0\n",
              "1095        1436513 2017-05-10      False    NaN\n",
              "1096        1436513 2017-05-09      False    NaN\n",
              "1097        1436513 2017-05-08      False    NaN\n",
              "1098        1436513 2017-05-07       True   75.0\n",
              "1099        1436513 2017-05-06       True   75.0\n",
              "1460        7651065 2017-06-21       True   79.0\n",
              "1461        7651065 2017-06-20       True   79.0\n",
              "1462        7651065 2017-06-19       True   79.0\n",
              "1463        7651065 2017-06-18       True   79.0\n",
              "1464        7651065 2017-06-17       True   79.0\n",
              "1825       12386020 2017-04-25      False    NaN\n",
              "1826       12386020 2017-04-24      False    NaN\n",
              "1827       12386020 2017-04-23      False    NaN\n",
              "1828       12386020 2017-04-22      False    NaN\n",
              "1829       12386020 2017-04-21      False    NaN\n",
              "...             ...        ...        ...    ...\n",
              "1306700    14852179 2017-08-20      False    NaN\n",
              "1306701    14852179 2017-08-19      False    NaN\n",
              "1306702    14852179 2017-08-18      False    NaN\n",
              "1306703    14852179 2017-08-17      False    NaN\n",
              "1306704    14852179 2017-08-16      False    NaN\n",
              "1307065     8373729 2017-05-18       True   69.0\n",
              "1307066     8373729 2017-05-17       True   69.0\n",
              "1307067     8373729 2017-05-16       True   69.0\n",
              "1307068     8373729 2017-05-15       True   69.0\n",
              "1307069     8373729 2017-05-14       True   69.0\n",
              "1307430    14844274 2017-06-22       True  150.0\n",
              "1307431    14844274 2017-06-21       True  150.0\n",
              "1307432    14844274 2017-06-20       True  150.0\n",
              "1307433    14844274 2017-06-19       True  150.0\n",
              "1307434    14844274 2017-06-18       True  150.0\n",
              "1307795    14585486 2017-09-05      False    NaN\n",
              "1307796    14585486 2017-09-04      False    NaN\n",
              "1307797    14585486 2017-09-03      False    NaN\n",
              "1307798    14585486 2017-09-02      False    NaN\n",
              "1307799    14585486 2017-09-01      False    NaN\n",
              "1308160    14603878 2017-09-05       True   59.0\n",
              "1308161    14603878 2017-09-04       True   59.0\n",
              "1308162    14603878 2017-09-03       True   59.0\n",
              "1308163    14603878 2017-09-02       True   59.0\n",
              "1308164    14603878 2017-09-01       True   59.0\n",
              "1308525    14504422 2017-06-21      False    NaN\n",
              "1308526    14504422 2017-06-20      False    NaN\n",
              "1308527    14504422 2017-06-19      False    NaN\n",
              "1308528    14504422 2017-06-18      False    NaN\n",
              "1308529    14504422 2017-06-17      False    NaN\n",
              "\n",
              "[17925 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-cjl8Nf-yFl2",
        "colab": {}
      },
      "source": [
        "def select_entries_after_activation_date(g):\n",
        "\n",
        "    listing_id = g.name\n",
        "    activation_date_df = listing_activation_dates.query(\"listing_id == @listing_id\")[\"date\"]\n",
        "    if activation_date_df.shape[0] > 0:        \n",
        "        activation_date = activation_date_df.iloc[0]\n",
        "#         print(\"activatation_date: \" + str(activation_date))\n",
        "#         print(g[\"date\"].dtype)\n",
        "#         print(type(activation_date))\n",
        "        return g[g[\"date\"] <= activation_date]\n",
        "    \n",
        "    \n",
        "cal_after_activation_dates =cal_by_listing_groups.apply(select_entries_after_activation_date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQqPxkspyFl5"
      },
      "source": [
        "### Select and add necessary variables to be used for predicting occupancy of property at given time of the year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZn6nZ1kyFl6",
        "colab": {}
      },
      "source": [
        "input_vars_from_listings = [\"neighbourhood_cleansed\", \n",
        "#                 \"neighbourhood_group_cleansed\",\n",
        "                \"city\",\n",
        "                \"state\",\n",
        "                \"zipcode\",\n",
        "                \"market\",\n",
        "                \"location_categorical\",\n",
        "                \"property_type\",\n",
        "                \"room_type\",\n",
        "                \"accommodates\",\n",
        "                \"bathrooms\",\n",
        "                \"bedrooms\",\n",
        "                \"beds\",\n",
        "                \"bed_type\",\n",
        "                \"square_feet\",\n",
        "                \"guests_included\",\n",
        "                \"minimum_nights\",\n",
        "                \"maximum_nights\",\n",
        "                \"review_scores_rating\",\n",
        "                \"review_scores_accuracy\",\n",
        "                  \"review_scores_cleanliness\",\n",
        "                  \"review_scores_checkin\",\n",
        "                  \"review_scores_communication\",\n",
        "                  \"review_scores_location\",\n",
        "                  \"review_scores_value\",\n",
        "#                   \"jurisdiction_names\",\n",
        "                  \"cancellation_policy\",\n",
        "#                   \"reviews_per_month\",\n",
        "                  \"number_of_reviews\"\n",
        "       ]\n",
        "amenity_variables = list(map(lambda amenity : \"amenity_\" + amenity, possible_amenities))\n",
        "input_vars_from_listings.extend(amenity_variables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bAlY2dhNyFl8",
        "colab": {}
      },
      "source": [
        "avg_price_by_date = calendar_cleaned.groupby(\"date\")[[\"date\", \"price\"]].agg([\"mean\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nHvyPFO7yFl_",
        "outputId": "8262593a-eb59-420f-de69-7a9db207b352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "prices_2016_17 = avg_price_by_date[avg_price_by_date.index >= calendar_cleaned[\"date\"].min()][avg_price_by_date.index <= calendar_cleaned[\"date\"].max()]\n",
        "dates = prices_2016_17.index\n",
        "months = mdates.MonthLocator()\n",
        "month_format = mdates.DateFormatter(\"%b\")\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(12,5)\n",
        "ax.plot(dates, prices_2016_17)\n",
        "ax.xaxis.set_major_locator(months)\n",
        "ax.xaxis.set_major_formatter(month_format)\n",
        "yticks = ax.get_yticks()\n",
        "# ax.set_yticklabels(['{}%'.format(y) for y in yticks])\n",
        "ax.set_xlabel(\"Month in 2016-17\")\n",
        "ax.set_ylabel(\"Average booking price in $ of property per night\")\n",
        "ax.set_title(\"Average booking price of properties listed on Airbnb in Boston in 2016-17\")\n",
        "plt.show()\n",
        "fig.savefig(project_dir + \"/images/average_booking_price_boston_2016_2017.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAFNCAYAAADLm0PlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_j7Rm21eyFmC",
        "outputId": "b84e2ac5-f12e-473c-c790-984b69880ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "prices_in_summer = avg_price_by_date.loc[pd.date_range('2017-05-01', '2017-05-31')]\n",
        "dates = prices_in_summer.index\n",
        "days = mdates.DayLocator()\n",
        "day_format = mdates.DateFormatter(\"%a\")\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(14,5)\n",
        "ax.plot(dates, prices_in_summer)\n",
        "ax.xaxis.set_major_locator(days)\n",
        "ax.xaxis.set_major_formatter(day_format)\n",
        "yticks = ax.get_yticks()\n",
        "ax.set_xlabel(\"Day in May 2017\")\n",
        "ax.set_ylabel(\"Average booking price in $ of property per night\")\n",
        "ax.set_title(\"Average booking price of properties listed on Airbnb in Boston in May 2017\")\n",
        "plt.show()\n",
        "fig.savefig(project_dir + \"/images/average_booking_price_boston_may_2017.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0cAAAFNCAYAAADLvhTMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A6mCFrGbyFmE",
        "colab": {}
      },
      "source": [
        "calendar_cleaned[\"month\"] = calendar_cleaned['date'].dt.month_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrqcGHh0U2nC",
        "colab": {}
      },
      "source": [
        "calendar_cleaned[\"year\"] = calendar_cleaned['date'].dt.year.astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-74JZiZ4yFmG",
        "colab": {}
      },
      "source": [
        "calendar_cleaned[\"day_of_week\"] = calendar_cleaned['date'].dt.weekday_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLrwU2ESyFmK",
        "colab": {}
      },
      "source": [
        "calendar_cleaned[\"week_of_month\"] = np.ceil(calendar_cleaned['date'].dt.day/7).astype(int).astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5dyd-aJyFmO",
        "outputId": "61c283ce-094e-49f3-e70f-c6ef5a97fc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "calendar_cleaned[\"week_of_month\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '5', '4', '3', '2'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NdkCljl2yFmQ",
        "colab": {}
      },
      "source": [
        "df = pd.merge(listings_cleaned, calendar_cleaned, left_on=\"id\", right_on=\"listing_id\", how=\"inner\", suffixes=(\"_listings\", \"_calendar\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iRFCrz2xyFmT",
        "colab": {}
      },
      "source": [
        "# This one consumes too much memory and time, but it can give more accurate price estimates for fulling missing values\n",
        "# g = df.groupby([\"listing_id\", \"month\", \"day_of_week\"]).apply(lambda x: x.sort_values(by=[\"date\"]))\n",
        "# g.loc[:, \"price_calendar\"] = g[\"price_calendar\"].fillna(method=\"ffill\")\n",
        "# df = g.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fMZaINnyyFma",
        "colab": {}
      },
      "source": [
        "g = df.groupby([\"listing_id\"]).apply(lambda x: x.sort_values(by=[\"date\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c3IAf2L6yFme",
        "colab": {}
      },
      "source": [
        "g.loc[:, \"price_calendar\"] = g[\"price_calendar\"].fillna(method=\"ffill\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3o1z2-ObyFmg",
        "colab": {}
      },
      "source": [
        "df = g.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OaESG-CDyFmj",
        "colab": {}
      },
      "source": [
        "input_vars_from_calendar = [\"year\", \"month\", \"day_of_week\", \"week_of_month\", \"price_calendar\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yVTYO-dKyFmm",
        "colab": {}
      },
      "source": [
        "all_input_vars = input_vars_from_listings + input_vars_from_calendar;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1du2p14wyFmp",
        "colab": {}
      },
      "source": [
        "df = df.dropna(subset=[\"available\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKvT7zDpyFmr"
      },
      "source": [
        "Select a sample of properties to be used as an environment of alternatives competing with the property to be booked that can have impact on whether the given property gets booked or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7icg112wyFms",
        "colab": {}
      },
      "source": [
        "start_date = df[\"date\"].min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7GfRVIP4yFmu",
        "colab": {}
      },
      "source": [
        "listing_ids_environment = list(df.query(\"date == @start_date\").drop_duplicates(['listing_id'])[\"listing_id\"].sample(100, random_state=42))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BwiI1-SWyFmx",
        "colab": {}
      },
      "source": [
        "X_with_env = df[all_input_vars + [\"listing_id\", \"date\"]].query(\"listing_id not in @listing_ids_environment\")\n",
        "for listing_id in listing_ids_environment:\n",
        "    listing_price_availability = df.query(\"listing_id == @listing_id\")[[\"price_calendar\", \"available\", \"date\"]]\n",
        "    X_with_env = pd.merge(X_with_env, listing_price_availability, left_on=\"date\", right_on=\"date\", how=\"inner\", suffixes=(\"\", \"_\"+str(listing_id)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OxZdQkPW165J"
      },
      "source": [
        "### Adding Normalized (Relative) Booking Prices for Properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IDysuQHByFm2"
      },
      "source": [
        "- Adding normalized prices for given property and all the properties used in the dataset serving as an indicator of competitive market condition. This will help ML models to easily learn conditions involving relative prices of the properties with much less complexity. \n",
        "- I am also retaining the absolute prices for properties in the environment and added one more field for storing total prices of all the properties in environment, so that the model can learn the current demand from the sample of prices from the overall market."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2UignVcEEzxP",
        "colab": {}
      },
      "source": [
        "price_columns_for_env = [col for col in X_with_env.columns if col.startswith(\"price_calendar\") and col != \"price_calendar\"]\n",
        "price_columns_for_prop_and_env = [col for col in X_with_env.columns if col.startswith(\"price_calendar\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OFBiFgbmLwqD",
        "colab": {}
      },
      "source": [
        "X_with_env.loc[:, \"total_env_prices\"] = X_with_env[price_columns_for_env].sum(axis=1)\n",
        "for price_column_for_prop_and_env in price_columns_for_prop_and_env:\n",
        "  X_with_env.loc[:, price_column_for_prop_and_env + \"_normalized\"] = X_with_env[price_column_for_prop_and_env] / X_with_env[\"total_env_prices\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BBuEBQs7L0wp",
        "colab": {}
      },
      "source": [
        "X_with_env = X_with_env.drop(columns=[\"price_calendar\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rQ0cdaxiyFm9",
        "colab": {}
      },
      "source": [
        "X = X_with_env.sort_values(by=[\"listing_id\", \"date\"]).drop(columns=[\"date\"]).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U5eKCWnOyFnC",
        "colab": {}
      },
      "source": [
        "y = df[[\"available\",\"listing_id\", \"date\"]].query(\"listing_id not in @listing_ids_environment\").sort_values(by=[\"listing_id\", \"date\"]).drop(columns=[\"date\"]).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X015ahxdyFnE",
        "outputId": "1470914f-92c3-4209-ba46-a3759f701012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1272390, 378)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zKituPM-yFnJ",
        "outputId": "839c6d5a-ded7-429a-8e11-d66a601fb48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1272390, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iov-mCvCyFnL",
        "outputId": "38185405-138e-4bfb-ff6c-48ec320d9acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape[0] == y.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IrvvVhTeyFnN",
        "outputId": "a4765a27-427e-4020-b4e0-7f5992eed392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(X[\"listing_id\"] == y[\"listing_id\"]).all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gF8FLl1FyFnP"
      },
      "source": [
        "### Fill missing values in numeric columns with mean of the corresponding column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aqj19ppXyFnQ",
        "colab": {}
      },
      "source": [
        "num_vars = X.select_dtypes(exclude=['object']).copy().columns\n",
        "def fill_mean (col):\n",
        "    return col.fillna(col.mean())\n",
        "X.loc[X.index, num_vars] = X[num_vars].apply(fill_mean, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "04PWLamayFnS"
      },
      "source": [
        "### Convert categorical variables into numeric variables with separate column for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-K9D2fhtyFnT",
        "colab": {}
      },
      "source": [
        "cat_vars = X.select_dtypes(include=['object']).copy().columns\n",
        "for var in  cat_vars:\n",
        "    # for each cat add dummy var, drop original column\n",
        "    X = pd.concat([X.drop(var, axis=1), pd.get_dummies(X[var], prefix=var, prefix_sep='_', drop_first=False, dummy_na=True)], axis=1)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kAIbSBBPyFnU"
      },
      "source": [
        "### Splitting data into training and test sets while making sure that no property listing is common between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k8chM7ieyFnV",
        "colab": {}
      },
      "source": [
        "unique_listing_ids = X[\"listing_id\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnvhg6G0yFnZ",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "listing_ids_train = np.random.choice(np.array(unique_listing_ids), size= int(0.70 * len(unique_listing_ids)), replace=False)\n",
        "listing_ids_test = [l for l in unique_listing_ids if l not in listing_ids_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2cnKLnGSyFnd",
        "colab": {}
      },
      "source": [
        "X_train = X.query(\"listing_id in @listing_ids_train\")\n",
        "y_train = y.query(\"listing_id in @listing_ids_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qS176-usyFnf",
        "outputId": "45f0ae23-de54-455a-aca2-341837bedf97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(X_train.index == y_train.index).all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VafLdZDRyFnh"
      },
      "source": [
        "I am using here only a smaller sample of training data to choose hyper parameters using cross validation technique to complete the experiments in timely manner. However, in real world scenario with availability of time, higher computational resources and memory, entire training dataset should be used for choosing optimal hyper parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pgoc-do-yFnh",
        "colab": {}
      },
      "source": [
        "X_train_sample = X_train.sample(100000, random_state=42)\n",
        "y_train_sample = y_train.loc[X_train_sample.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UgKIcS2eyFnj",
        "outputId": "ffc6fc3b-9068-425e-e45b-18f59fe11932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(X_train_sample[\"listing_id\"] == y_train_sample[\"listing_id\"]).all()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iRBUlZk_yFnl",
        "outputId": "d3f5e61d-d633-424a-9c2c-1daea41346ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_sample.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 675)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2xKKD-syFnn",
        "outputId": "cb435007-ad8d-47f1-c154-53e7fda1d51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train_sample.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IzkKyvnayFnp",
        "colab": {}
      },
      "source": [
        "X_test = X.query(\"listing_id in @listing_ids_test\").drop(columns=[\"listing_id\"])\n",
        "y_test = y.query(\"listing_id in @listing_ids_test\").drop(columns=[\"listing_id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R-TZu3yEyFns",
        "colab": {}
      },
      "source": [
        "X_train_sample.to_csv(data_dir + \"/X_train_sample.csv\", index=False)\n",
        "y_train_sample.to_csv(data_dir + \"/y_train_sample.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pATjxaMgNPxu",
        "colab": {}
      },
      "source": [
        "X_train.to_csv(data_dir + \"/X_train.csv\", index=False)\n",
        "y_train.to_csv(data_dir + \"/y_train.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fe5cjok3yFnv",
        "colab": {}
      },
      "source": [
        "X_test.to_csv(data_dir + \"/X_test.csv\", index=False)\n",
        "y_test.to_csv(data_dir + \"/y_test.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FMRN1Rk4yFnx",
        "outputId": "3540b98d-1caf-4b81-c290-2e84b12931e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_train[\"available\"].value_counts()/y_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.510761\n",
              "True     0.489239\n",
              "Name: available, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AmoTCEKNyFn0"
      },
      "source": [
        "Considering the ratio of samples classified for output True and False, the data looks to be balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeZg5olN1122",
        "colab_type": "text"
      },
      "source": [
        "## Training Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ue7tJzWpyFn1"
      },
      "source": [
        "### Preparing cross validation splits to into training and test sets while making sure that no property listing is common between them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6_MbXYcesWX",
        "colab_type": "text"
      },
      "source": [
        "I haven't used `MyGridSearchCV` class anywhere in this notebook, \n",
        "as I decided to use Tree of Parzen Estimators Algorithm and Bayesian Optimization algo\n",
        "implemented in Hyperopt and Scikit Optimize \n",
        "for quickly narrowing down the optimal hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Re7hJ1cRyFn1",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class MyGridSearchCV(object):\n",
        "    \n",
        "    def __init__(self, estimator, param_grid, cv=3):\n",
        "        self.estimator = estimator\n",
        "        self.param_grid = param_grid\n",
        "        self.best_score = -math.inf\n",
        "        self.best_estimator = None\n",
        "        self.best_estimator_scores_mean = -math.inf\n",
        "        self.best_estimator_scores_stdev = -math.inf\n",
        "        self.best_params= None\n",
        "        self.cv = cv       \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        for param_point in self.get_param_grid_points():\n",
        "            def splits(array, k):\n",
        "                splits = []\n",
        "                \n",
        "                for i in range(k):\n",
        "                    split_length = math.ceil(len(array)/k)\n",
        "                    split = []\n",
        "                    for j in range(i * split_length, (i+1) * split_length):\n",
        "                        if j < len(array):\n",
        "                            split.append(array[j])\n",
        "                        \n",
        "                    splits.append(split)\n",
        "                cvs = []\n",
        "                for i, split in enumerate(splits):\n",
        "                    train = []\n",
        "                    for j, other_split in enumerate(splits):\n",
        "                        if i != j:\n",
        "                            train += other_split\n",
        "                    test = [] + split\n",
        "                    cvs.append((train, test))\n",
        "                return cvs\n",
        "                    \n",
        "            scores_for_point = []\n",
        "            estimator = clone(self.estimator)\n",
        "            estimator.set_params(**param_point)\n",
        "            for l_train, l_test in splits(list(X[\"listing_id\"].unique()), k=self.cv):                \n",
        "                X_train = X.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "                X_test = X.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
        "                y_train = y.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "                y_test = y.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])                \n",
        "                estimator.fit(X_train, y_train.values.ravel())\n",
        "                y_preds = estimator.predict(X_test)\n",
        "                f1_score_1 = f1_score(y_test, y_preds, pos_label=True)\n",
        "                f1_score_0 = f1_score(y_test, y_preds, pos_label=False)\n",
        "                score = min([f1_score_1, f1_score_0])\n",
        "                scores_for_point.append(score)\n",
        "                \n",
        "            mean_score = np.mean(scores_for_point)\n",
        "            if mean_score > self.best_estimator_scores_mean:\n",
        "                self.best_estimator_scores_mean = mean_score\n",
        "                self.best_estimator_scores_stdev = np.std(scores_for_point)\n",
        "                self.best_estimator = estimator\n",
        "                self.best_params = self.best_estimator.get_params()\n",
        "                self.best_score = self.best_estimator_scores_mean\n",
        "   \n",
        "            \n",
        "    def get_param_grid_points(self):\n",
        "        points = [{}]\n",
        "        for param, values in self.param_grid.items():\n",
        "            new_points = []\n",
        "            for point in points:\n",
        "                for value in values:                    \n",
        "                    new_point = point.copy()\n",
        "                    new_point[param]= value\n",
        "                    new_points.append(new_point)\n",
        "            points = new_points\n",
        "        return points\n",
        "    \n",
        "    def print_best(self):\n",
        "        print(\"Best score:\")\n",
        "        print(self.best_score)\n",
        "        print(\"Best params:\")\n",
        "        print(self.best_params)\n",
        "        print(\"Best estimator scores mean:\")\n",
        "        print(self.best_estimator_scores_mean)\n",
        "        print(\"Best estimator scores stdev:\")\n",
        "        print(self.best_estimator_scores_stdev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYhzvdZPfDLu",
        "colab_type": "text"
      },
      "source": [
        "`my_cross_val_score` is used in calculating the score after each cross validation step\n",
        "while tuning hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LZiAQup7yFn3",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def my_cross_val_score(estimator, X, y):\n",
        "    def splits(array, k):\n",
        "        splits = []\n",
        "\n",
        "        for i in range(k):\n",
        "            split_length = math.ceil(len(array)/k)\n",
        "            split = []\n",
        "            for j in range(i * split_length, (i+1) * split_length):\n",
        "                if j < len(array):\n",
        "                    split.append(array[j])\n",
        "\n",
        "            splits.append(split)\n",
        "        cvs = []\n",
        "        for i, split in enumerate(splits):\n",
        "            train = []\n",
        "            for j, other_split in enumerate(splits):\n",
        "                if i != j:\n",
        "                    train += other_split\n",
        "            test = [] + split\n",
        "            cvs.append((train, test))\n",
        "        return cvs\n",
        "\n",
        "    scores_for_point = []\n",
        "    for l_train, l_test in splits(list(X[\"listing_id\"].unique()), k=5):\n",
        "        X_train = X.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "        y_train = y.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "        X_test = X.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
        "        y_test = y.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
        "        estimator.fit(X=X_train, y=y_train.astype('int').values.ravel())\n",
        "        y_preds = estimator.predict(X_test)\n",
        "        f1_score_1 = f1_score(y_test, y_preds, pos_label=True)\n",
        "        f1_score_0 = f1_score(y_test, y_preds, pos_label=False)\n",
        "        score = min([f1_score_1, f1_score_0])\n",
        "        scores_for_point.append(score)\n",
        "\n",
        "    mean_score = np.mean(scores_for_point)\n",
        "    return mean_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY5kFPkZFrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import decimal\n",
        "\n",
        "def float_range(start, stop, step):\n",
        "    start = decimal.Decimal(start)\n",
        "    stop = decimal.Decimal(stop)\n",
        "    step = decimal.Decimal(step)\n",
        "    while (start < stop):\n",
        "        yield float(start)\n",
        "        start += step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eOnt42JDNenx",
        "colab": {}
      },
      "source": [
        "X_train = pd.read_csv(data_dir + \"/X_train.csv\")\n",
        "y_train = pd.read_csv(data_dir + \"/y_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxBAn0bSDdVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_sample = pd.read_csv(data_dir + \"/X_train_sample.csv\")\n",
        "y_train_sample = pd.read_csv(data_dir + \"/y_train_sample.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jDlMsE3KyFn6"
      },
      "source": [
        "### Decision Tree Classifier for testing setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nt75dwmnyFn6"
      },
      "source": [
        "I will be using **Tree of Parzen Estimators** algorithm implemented in **Hyperopt** library for choosing hyper parameters to be evaluated to find the optimal ones that maximizes the score = min(f1_score_for_positive_class, f1_score_for_negative_class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uAQq07TayFn7",
        "outputId": "edf0b164-651d-4dad-d6ee-d3462e2d050f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def objective_dtc(params):\n",
        "    clf = DecisionTreeClassifier()\n",
        "    clf.set_params(**params)    \n",
        "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "    print(params)\n",
        "    print(\"score: \" + str(score))\n",
        "    return -score\n",
        "\n",
        "dtc_param_space = {\n",
        "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", range(1,6,2)),\n",
        "    \"min_samples_split\": hp.choice(\"min_samples_split\", [2*x for x in range(1,11,2)]),\n",
        "    \"max_depth\": hp.choice(\"max_depth\", [2**x for x in range(2,11)]),    \n",
        "    \"random_state\": hp.choice(\"random_state\", [42])\n",
        "}\n",
        "start_time = time.time()\n",
        "best_params_dtc = space_eval(dtc_param_space, fmin(objective_dtc, dtc_param_space, algo=tpe.suggest, max_evals=50))\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "print (\"Best params: \")\n",
        "print (best_params_dtc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 64, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6383529765367142\n",
            "{'max_depth': 32, 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.6351913174016902\n",
            "{'max_depth': 32, 'min_samples_leaf': 1, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6383529005456686\n",
            "{'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6271247623820407\n",
            "{'max_depth': 512, 'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6360080143076388\n",
            "{'max_depth': 32, 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.6351913174016902\n",
            "{'max_depth': 128, 'min_samples_leaf': 1, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6359662427549271\n",
            "{'max_depth': 512, 'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6360080143076388\n",
            "{'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.5919900661848676\n",
            "{'max_depth': 128, 'min_samples_leaf': 5, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6390527615737718\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 128, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.6338562071482476\n",
            "{'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.5919900661848676\n",
            "{'max_depth': 128, 'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6360080143076388\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6427990843772236\n",
            "{'max_depth': 128, 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.6355047049628382\n",
            "{'max_depth': 32, 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.6351913174016902\n",
            "{'max_depth': 512, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.6355047049628382\n",
            "{'max_depth': 64, 'min_samples_leaf': 3, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6364001801277773\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 42}\n",
            "score: 0.6395901545193048\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 1024, 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 42}\n",
            "score: 0.6355047049628382\n",
            "{'max_depth': 256, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 42}\n",
            "score: 0.6395901545193048\n",
            "{'max_depth': 256, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "{'max_depth': 1024, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "{'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.627913295748235\n",
            "{'max_depth': 64, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.6355047049628382\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 42}\n",
            "score: 0.6395901545193048\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6432679517991982\n",
            "{'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.627287655003484\n",
            "{'max_depth': 256, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "{'max_depth': 1024, 'min_samples_leaf': 3, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6353509697742981\n",
            "{'max_depth': 64, 'min_samples_leaf': 5, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6390527615737718\n",
            "{'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.5919900661848676\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.6401762789089033\n",
            "{'max_depth': 32, 'min_samples_leaf': 3, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6355131785409325\n",
            "{'max_depth': 512, 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 42}\n",
            "score: 0.6355047049628382\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6411031127880163\n",
            "{'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6274999796686329\n",
            "{'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 42}\n",
            "score: 0.5919900661848676\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 6, 'random_state': 42}\n",
            "score: 0.6377591052585515\n",
            "{'max_depth': 32, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6367427608335664\n",
            "{'max_depth': 512, 'min_samples_leaf': 3, 'min_samples_split': 14, 'random_state': 42}\n",
            "score: 0.6364001801277773\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6427990843772236\n",
            "{'max_depth': 128, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
            "score: 0.6365707502786513\n",
            "100%|██████████| 50/50 [1:01:19<00:00, 76.13s/it, best loss: -0.6432679517991982]\n",
            "Elapsed computation time: 61.324 mins\n",
            "Best params: \n",
            "{'max_depth': 16, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "72jW97tJyFn9"
      },
      "source": [
        "After having evaluated the approximate optimal value for max-depth hyper parameter to be around 16, I am using **Bayesian Optimization** technique implemented in `gp_minimize` method of **Scikit Optimize** package to choose precisely optimal hyper parameters that maximizes the score = min(f1_score_for_positive_class, f1_score_for_negative_class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--zQN1IOyFn9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21bb3096-8574-4f65-fba6-799f4c99a68f"
      },
      "source": [
        "def objective_dtc(params):\n",
        "    clf = DecisionTreeClassifier(\n",
        "        max_depth = params[0],\n",
        "        min_samples_leaf = params[1],\n",
        "        min_samples_split = params[2],\n",
        "        random_state = 42\n",
        "    )\n",
        "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "    print (\"Currently evaluating params:\")\n",
        "    print({\n",
        "      \"max_depth\": params[0],\n",
        "      \"min_samples_leaf\": params[1],\n",
        "      \"min_samples_split\": params[2]\n",
        "    })\n",
        "    print (\"score: \" + str(score))\n",
        "    return -score\n",
        "start_time = time.time()\n",
        "dtc_opt_result = gp_minimize(\n",
        "    func=objective_dtc,\n",
        "    dimensions=[\n",
        "        (8, 30),\n",
        "        (1, 10),\n",
        "        (2, 20)\n",
        "    ],\n",
        "    random_state=42\n",
        ")\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "best_params_list_dtc = dtc_opt_result.x\n",
        "best_score_dtc = -dtc_opt_result.fun\n",
        "best_params_dtc = {\n",
        "    \"max_depth\": best_params_list_dtc[0],\n",
        "    \"min_samples_leaf\": best_params_list_dtc[1],\n",
        "    \"min_samples_split\": best_params_list_dtc[2]\n",
        "}\n",
        "print (\"Best score: \" + str(best_score_dtc))\n",
        "print (\"Best params: \" + str(best_params_dtc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 26, 'min_samples_leaf': 3, 'min_samples_split': 16}\n",
            "score: 0.6399553867559484\n",
            "Currently evaluating params:\n",
            "{'max_depth': 21, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "score: 0.6370727220008563\n",
            "Currently evaluating params:\n",
            "{'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "score: 0.6431056262690623\n",
            "Currently evaluating params:\n",
            "{'max_depth': 22, 'min_samples_leaf': 2, 'min_samples_split': 15}\n",
            "score: 0.637226439312167\n",
            "Currently evaluating params:\n",
            "{'max_depth': 29, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6393042355339641\n",
            "Currently evaluating params:\n",
            "{'max_depth': 22, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "score: 0.6389019073161124\n",
            "Currently evaluating params:\n",
            "{'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 9}\n",
            "score: 0.6416607409817947\n",
            "Currently evaluating params:\n",
            "{'max_depth': 9, 'min_samples_leaf': 10, 'min_samples_split': 6}\n",
            "score: 0.6401659532038295\n",
            "Currently evaluating params:\n",
            "{'max_depth': 10, 'min_samples_leaf': 7, 'min_samples_split': 9}\n",
            "score: 0.6371484863972355\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 17}\n",
            "score: 0.6381194700380449\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6270872999521974\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6263068409343127\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "score: 0.6340758542681787\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6340758542681787\n",
            "Currently evaluating params:\n",
            "{'max_depth': 29, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6339028772994016\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6347641234181521\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6340758542681787\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6273332884984797\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 19}\n",
            "score: 0.6270872999521974\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "score: 0.6327217690117365\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 6, 'min_samples_split': 20}\n",
            "score: 0.6398015881433822\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6324654362777882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 6, 'min_samples_split': 20}\n",
            "score: 0.6398015881433822\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "score: 0.6367792739663631\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
            "score: 0.6275653294257191\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "score: 0.6270085278963564\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "score: 0.6367792739663631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6340758542681787\n",
            "Currently evaluating params:\n",
            "{'max_depth': 30, 'min_samples_leaf': 5, 'min_samples_split': 11}\n",
            "score: 0.6364277150089812\n",
            "Currently evaluating params:\n",
            "{'max_depth': 14, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6371544904317694\n",
            "Currently evaluating params:\n",
            "{'max_depth': 9, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6401659532038295\n",
            "Currently evaluating params:\n",
            "{'max_depth': 16, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.641837941721267\n",
            "Currently evaluating params:\n",
            "{'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6270872999521974\n",
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6419302505483339\n",
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6431307571878134\n",
            "Currently evaluating params:\n",
            "{'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6366216277646688\n",
            "Currently evaluating params:\n",
            "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6377404558175962\n",
            "Currently evaluating params:\n",
            "{'max_depth': 12, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6401460586754734\n",
            "Currently evaluating params:\n",
            "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6400752104628408\n",
            "Currently evaluating params:\n",
            "{'max_depth': 27, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6352504521762865\n",
            "Currently evaluating params:\n",
            "{'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6393812996707893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 14, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6371544904317694\n",
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6431307571878134\n",
            "Currently evaluating params:\n",
            "{'max_depth': 18, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6408505043782944\n",
            "Currently evaluating params:\n",
            "{'max_depth': 11, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6398603499571225\n",
            "Currently evaluating params:\n",
            "{'max_depth': 24, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "score: 0.6351947365539108\n",
            "Currently evaluating params:\n",
            "{'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6420295761164818\n",
            "Currently evaluating params:\n",
            "{'max_depth': 27, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6352504521762865\n",
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.641005827331264\n",
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6373755669695819\n",
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6356352758740569\n",
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 23, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6360065441798284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 11, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6398603499571225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6420295761164818\n",
            "Currently evaluating params:\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6434103057340579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 11, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6398603499571225\n",
            "Currently evaluating params:\n",
            "{'max_depth': 28, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6407555892821082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6398369724051174\n",
            "Currently evaluating params:\n",
            "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 19}\n",
            "score: 0.637022871551632\n",
            "Currently evaluating params:\n",
            "{'max_depth': 13, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "score: 0.6354758581162363\n",
            "Currently evaluating params:\n",
            "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6365910671707964\n",
            "Currently evaluating params:\n",
            "{'max_depth': 28, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6333045670840178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "score: 0.6409464271491674\n",
            "Currently evaluating params:\n",
            "{'max_depth': 21, 'min_samples_leaf': 10, 'min_samples_split': 19}\n",
            "score: 0.6377681215251407\n",
            "Currently evaluating params:\n",
            "{'max_depth': 18, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6402580664833585\n",
            "Currently evaluating params:\n",
            "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 19}\n",
            "score: 0.6417703331070956\n",
            "Currently evaluating params:\n",
            "{'max_depth': 24, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6369209726760905\n",
            "Currently evaluating params:\n",
            "{'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.639093146627132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6431307571878134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 26, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "score: 0.6382926601374392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6417703331070956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 22, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6341484581302013\n",
            "Currently evaluating params:\n",
            "{'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6371352291396003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 20}\n",
            "score: 0.6434103057340579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 12, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6401460586754734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6420295761164818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently evaluating params:\n",
            "{'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "score: 0.6445080675393088\n",
            "Currently evaluating params:\n",
            "{'max_depth': 19, 'min_samples_leaf': 1, 'min_samples_split': 19}\n",
            "score: 0.6412114636345012\n",
            "Currently evaluating params:\n",
            "{'max_depth': 28, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "score: 0.6365542900313541\n",
            "Currently evaluating params:\n",
            "{'max_depth': 24, 'min_samples_leaf': 10, 'min_samples_split': 20}\n",
            "score: 0.6369209726760905\n",
            "Elapsed computation time: 115.392 mins\n",
            "Best score: 0.6445080675393088\n",
            "Best params: {'max_depth': 17, 'min_samples_leaf': 10, 'min_samples_split': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4Jd7ECyk-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "# best_params_dtc = {'max_depth': 15, 'min_samples_leaf': 5, 'min_samples_split': 18, 'random_state': 42}\n",
        "dtc.set_params(**best_params_dtc)\n",
        "dtc.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
        "pickle.dump(dtc, open(data_dir + '/dtc_best.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zZQsmGobyFn_"
      },
      "source": [
        "## Ensemble Learners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWep1DD0lXFH",
        "colab_type": "text"
      },
      "source": [
        "### Extreme Gradient Boosting (XGBoost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10FalIJSFWlq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "09d3a5d5-c6cb-4da4-8fea-9846b2200b74"
      },
      "source": [
        "def objective_xgb(params):\n",
        "    clf = XGBClassifier()\n",
        "    clf.set_params(**params)    \n",
        "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "    print(params)\n",
        "    print(\"score: \" + str(score))\n",
        "    return -score\n",
        "\n",
        "xgb_param_space = {    \n",
        "    \"max_depth\": hp.choice(\"max_depth\", range(2, 11, 1)),\n",
        "    \"n_estimators\": hp.choice(\"n_estimators\", range(100, 1001, 100)),\n",
        "    \"random_state\": hp.choice(\"random_state\", [42])\n",
        "}\n",
        "start_time = time.time()\n",
        "best_params_xgb = space_eval(xgb_param_space, fmin(objective_xgb, xgb_param_space, algo=tpe.suggest, max_evals=25))\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "print (\"Best params: \")\n",
        "print (best_params_xgb)\n",
        "xgb = XGBClassifier()\n",
        "xgb.set_params(**best_params_xgb)\n",
        "xgb.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]).values.ravel())\n",
        "pickle.dump(gb, open(data_dir + '/xgb_best.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 2, 'n_estimators': 600, 'random_state': 42}\n",
            "score: 0.6807125642558571\n",
            "  4%|▍         | 1/25 [40:07<16:03:06, 2407.77s/it, best loss: -0.6807125642558571]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xzjK61a0yFoH"
      },
      "source": [
        "### Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9_PB6UPGrKL",
        "colab": {}
      },
      "source": [
        "def objective_gb(params):\n",
        "    clf = GradientBoostingClassifier()\n",
        "    clf.set_params(**params)    \n",
        "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "    print(params)\n",
        "    print(\"score: \" + str(score))\n",
        "    return -score\n",
        "\n",
        "gb_param_space = {    \n",
        "    \"max_depth\": hp.choice(\"max_depth\", range(2, 11, 1)),\n",
        "    \"n_estimators\": hp.choice(\"n_estimators\", range(100, 1001, 100)),\n",
        "    \"random_state\": hp.choice(\"random_state\", [42])\n",
        "}\n",
        "start_time = time.time()\n",
        "best_params_gb = space_eval(gb_param_space, fmin(objective_gb, gb_param_space, algo=tpe.suggest, max_evals=25))\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "print (\"Best params: \")\n",
        "print (best_params_gb)\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.set_params(**best_params_gb)\n",
        "gb.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]).values.ravel())\n",
        "pickle.dump(gb, open(data_dir + '/gb_best.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C4sZ8a7qyFoA"
      },
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J3dlw7gAyFoB",
        "colab": {}
      },
      "source": [
        "def objective_ada(params):\n",
        "    clf = AdaBoostClassifier(DecisionTreeClassifier())\n",
        "    clf.set_params(**params)    \n",
        "    score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "    print(params)\n",
        "    print(\"score: \" + str(score))\n",
        "    return -score\n",
        "ada_param_space = {\n",
        "    \"base_estimator__max_depth\": hp.choice(\"base_estimator__max_depth\", range(2,11,1)),\n",
        "    \"n_estimators\": hp.choice(\"n_estimators\", range(100, 1001, 100)),\n",
        "    \"random_state\": hp.choice(\"random_state\", [42])\n",
        "}\n",
        "start_time = time.time()\n",
        "best_params_ada = space_eval(ada_param_space, fmin(objective_ada, ada_param_space, algo=tpe.suggest, max_evals=25))\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "print (\"Best params: \")\n",
        "print (best_params_ada)\n",
        "ada = AdaBoostClassifier(DecisionTreeClassifier())\n",
        "ada.set_params(**best_params_ada)\n",
        "ada.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]))\n",
        "pickle.dump(ada, open(data_dir + '/ada_best.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oHoXclxZyFoM"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUFS1poxIizF",
        "colab_type": "text"
      },
      "source": [
        "The execution of even one iteration of of this algorithm appears to be very slow on this dataset. I have just kept this here for reference in case I want to try it in future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z8g0jV5eyFoM",
        "colab": {}
      },
      "source": [
        "# def objective_svm(params):\n",
        "#     clf = SVC()\n",
        "#     clf.set_params(**params)\n",
        "#     score = my_cross_val_score(clf, X=X_train_sample, y=y_train_sample)\n",
        "#     print(params)\n",
        "#     print(\"score: \" + str(score))\n",
        "#     return -score\n",
        "# svm_param_space = {\n",
        "#     \"kernel\": hp.choice(\"kernel\", ['rbf']),\n",
        "#     \"gamma\": hp.choice(\"gamma\", [0.001, 0.005, 0.01, 0.1, 1]),\n",
        "#     \"C\": hp.choice(\"C\", [1, 5, 10, 50, 100, 500, 1000]),\n",
        "#     \"random_state\": hp.choice(\"random_state\", [42]),\n",
        "  \n",
        "# }\n",
        "# start_time = time.time()\n",
        "# best_params_svm = space_eval(svm_param_space, fmin(objective_svm, svm_param_space, algo=tpe.suggest, max_evals=50))\n",
        "# elapsed_time = (time.time() - start_time) / 60\n",
        "# print('Elapsed computation time: {:.3f} mins'.format(elapsed_time))\n",
        "# print (\"Best params: \")\n",
        "# print (best_params_svm)\n",
        "# svm = SVC()\n",
        "# best_params_svm[\"probability\"] = True\n",
        "# svm.set_params(**best_params_svm)\n",
        "# svm.fit(X=X_train.drop(columns=[\"listing_id\"]), y=y_train.drop(columns=[\"listing_id\"]).values.ravel())\n",
        "# pickle.dump(svm, open(data_dir + '/svm_best.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gujejNkkyFoO"
      },
      "source": [
        "## Neural Network with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFJ8DoLOjYE_",
        "colab_type": "text"
      },
      "source": [
        "For deciding number of hidden layers and number of neurons in each layer, I followed following rules of thumb suggested by some ML researches on discussion forums related to machine learning and statistics.\n",
        "- The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
        "- The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
        "- The number of hidden neurons should be less than twice the size of the input layer.  \n",
        "\n",
        "While these values can be a good starting point, the most optimal values for number and width of hidden layers can be decided by treating those numbers as hyperparameters to be tuned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FQiNCpwfyFoO",
        "colab": {}
      },
      "source": [
        "def make_model(n_features, n_hidden_layers, n_neurons_per_layer, reduction_in_num_of_neurons_per_layer, learn_rate):\n",
        "    model = Sequential()    \n",
        "    model.add(Dense(n_neurons_per_layer, input_shape=(n_features,), kernel_initializer='glorot_normal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    for i in range(1, n_hidden_layers):\n",
        "      model.add(Dense(int(n_neurons_per_layer * (1-reduction_in_num_of_neurons_per_layer)), kernel_initializer='glorot_normal'))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(BatchNormalization())\n",
        "      model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer=Adam(lr=learn_rate),\n",
        "                metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmCjgWC57yn9",
        "colab_type": "text"
      },
      "source": [
        "### Hyper Parameter Tuner for Deep Learning model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGBuaLD4Fks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HyperTuner(object):\n",
        "    \n",
        "    def __init__(self, param_grid, cv=3):\n",
        "        self.param_grid = param_grid\n",
        "        self.best_score = -math.inf\n",
        "        self.best_estimator_scores_median = -math.inf\n",
        "        self.best_estimator_scores_mean = -math.inf\n",
        "        self.best_estimator_scores_stdev = -math.inf\n",
        "        self.best_params= None\n",
        "        self.cv = cv       \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        for param_point in self.get_param_grid_points():\n",
        "            print (\"Evaluating Parameter Values:\")\n",
        "            print (param_point)\n",
        "            def splits(array, k):\n",
        "                splits = []\n",
        "                \n",
        "                for i in range(k):\n",
        "                    split_length = math.ceil(len(array)/k)\n",
        "                    split = []\n",
        "                    for j in range(i * split_length, (i+1) * split_length):\n",
        "                        if j < len(array):\n",
        "                            split.append(array[j])\n",
        "                        \n",
        "                    splits.append(split)\n",
        "                cvs = []\n",
        "                for i, split in enumerate(splits):\n",
        "                    train = []\n",
        "                    for j, other_split in enumerate(splits):\n",
        "                        if i != j:\n",
        "                            train += other_split\n",
        "                    test = [] + split\n",
        "                    cvs.append((train, test))\n",
        "                return cvs\n",
        "                    \n",
        "            scores_for_point = []\n",
        "            n_features = len(X.drop(columns=[\"listing_id\"]).columns)\n",
        "            n_hidden_layers = param_point[\"n_hidden_layers\"]\n",
        "            n_neurons_per_layer = param_point[\"n_neurons_per_layer\"]\n",
        "            reduction_in_num_of_neurons_per_layer = param_point[\"reduction_in_num_of_neurons_per_layer\"]\n",
        "            learn_rate = param_point[\"learn_rate\"]\n",
        "\n",
        "            for l_train, l_test in splits(list(X[\"listing_id\"].unique()), k=self.cv):   \n",
        "                model = make_model(n_features, n_hidden_layers, n_neurons_per_layer, reduction_in_num_of_neurons_per_layer, learn_rate)             \n",
        "                X_train = X.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "                X_test = X.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])\n",
        "                y_train = y.query(\"listing_id in @l_train\").drop(columns=[\"listing_id\"])\n",
        "                y_test = y.query(\"listing_id in @l_test\").drop(columns=[\"listing_id\"])                \n",
        "                model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0,\n",
        "                callbacks=[\n",
        "                  EarlyStopping(monitor='val_loss', verbose=0, patience=3),\n",
        "                  ModelCheckpoint(data_dir + '/nn_best_model_temp.h5', monitor='val_loss', verbose=0)\n",
        "                 ])\n",
        "                model.load_weights(data_dir + \"/nn_best_model_temp.h5\")\n",
        "                y_preds = model.predict_classes(X_test)\n",
        "                f1_score_1 = f1_score(y_test, y_preds, pos_label=True)\n",
        "                f1_score_0 = f1_score(y_test, y_preds, pos_label=False)\n",
        "                score = min([f1_score_1, f1_score_0])\n",
        "                scores_for_point.append(score)\n",
        "                \n",
        "            median_score = np.median(scores_for_point)\n",
        "            \n",
        "            print (\"Done evaluation param point.\\nScore: \" + str(median_score))\n",
        "            print (\"-------------------------------------\")\n",
        "            if median_score > self.best_estimator_scores_median:\n",
        "                self.best_estimator_scores_mean = np.mean(scores_for_point)\n",
        "                self.best_estimator_scores_median = median_score\n",
        "                self.best_estimator_scores_stdev = np.std(scores_for_point)\n",
        "                self.best_params = param_point\n",
        "                self.best_score = self.best_estimator_scores_median\n",
        "\n",
        "        print (\"Finished evaluating all values for hyper parameters.\")\n",
        "        print (\"Best Parameter Values:\")\n",
        "        print (self.best_params)\n",
        "        print (\"Best Score (median of validation scores): \" + str(median_score))\n",
        "        \n",
        "            \n",
        "    def get_param_grid_points(self):\n",
        "        points = [{}]\n",
        "        for param, values in self.param_grid.items():\n",
        "            new_points = []\n",
        "            for point in points:\n",
        "                for value in values:                    \n",
        "                    new_point = point.copy()\n",
        "                    new_point[param]= value\n",
        "                    new_points.append(new_point)\n",
        "            points = new_points\n",
        "        return points\n",
        "    \n",
        "    def print_best(self):\n",
        "        print(\"Best score (median of validation scores):\")\n",
        "        print(self.best_score)\n",
        "        print(\"Best params:\")\n",
        "        print(self.best_params)\n",
        "        print(\"Best estimator scores mean:\")\n",
        "        print(self.best_estimator_scores_mean)\n",
        "        print(\"Best estimator scores stdev:\")\n",
        "        print(self.best_estimator_scores_stdev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic6SwXikEkR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I have fixed hyper parameters to save time and memory consumption\n",
        "# they can be tested by specifying values in the range as shown in comments\n",
        "\n",
        "hyper_tuner = HyperTuner(param_grid={\n",
        "    \"n_hidden_layers\": [4], # [3,4,5]\n",
        "    \"n_neurons_per_layer\": [100], # [50, 100, 150, 200]\n",
        "    \"reduction_in_num_of_neurons_per_layer\": [0.2], # [0, 0.2, 0.5]\n",
        "    \"learn_rate\": [0.01] # [0.001, 0.01, 0.1]\n",
        "}, cv=3)\n",
        "hyper_tuner.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZB2dv4-SG0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyper_tuner.print_best()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ-_OdCQEOV8",
        "colab_type": "text"
      },
      "source": [
        "Preparing the best model with optimal values of hyper parameters.\n",
        "\n",
        "- I have used Early stopping to prevent the neural network overfit to the training data while being trained on same data through multiple epochs.  \n",
        "- I have also used ModelCheckpoint that saves the weights of last best performing model, so that I can set early stopping patience to greater zero and it allows a few epochs to be executed to confirm that the performance of model on unseen data is unlikely to improve by running any more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4mSJXo9EJUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = len(X_train.drop(columns=[\"listing_id\"]).columns)\n",
        "n_hidden_layers = hyper_tuner.best_params[\"n_hidden_layers\"]\n",
        "n_neurons_per_layer = hyper_tuner.best_params[\"n_neurons_per_layer\"]\n",
        "learn_rate = 0.01           \n",
        "nn_model = make_model(n_features, n_hidden_layers, n_neurons_per_layer, learn_rate)\n",
        "validation_listing_ids = list(X_train[[\"listing_id\"]].drop_duplicates([\"listing_id\"]).sample(frac=0.1)[\"listing_id\"])\n",
        "X_val_nn = X_train.query(\"listing_id in @validation_listing_ids\").drop(columns=[\"listing_id\"])\n",
        "y_val_nn = y_train.query(\"listing_id in @validation_listing_ids\").drop(columns=[\"listing_id\"])\n",
        "X_train_nn = X_train.query(\"listing_id not in @validation_listing_ids\").drop(columns=[\"listing_id\"])\n",
        "y_train_nn = y_train.query(\"listing_id not in @validation_listing_ids\").drop(columns=[\"listing_id\"])       \n",
        "nn_model.fit(X_train_nn, y_train_nn, validation_data=(X_val_nn, y_val_nn), epochs=50, verbose=1,\n",
        "        callbacks=[\n",
        "          EarlyStopping(monitor='val_loss', verbose=1, patience=5),\n",
        "          ModelCheckpoint(data_dir + '/nn_best_model_cv.h5', monitor='val_loss', verbose=1)\n",
        "        ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3x72Fb-HgA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_model.load_weights(data_dir + '/nn_best_model_cv.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TaYcH-S3yFof"
      },
      "source": [
        "## Prediction & Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GlqBxISCyFof",
        "colab": {}
      },
      "source": [
        "X_test = pd.read_csv(data_dir + \"/X_test.csv\")\n",
        "y_test = pd.read_csv(data_dir + \"/y_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK8LcQkCY8Tv",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-K5fkQ_yFom",
        "colab": {}
      },
      "source": [
        "nn_model = load_model(data_dir + \"/nn_best_model_cv.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGvXwKHuyFoq",
        "colab": {}
      },
      "source": [
        "nn_model.evaluate(x=X_test,y=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Df89mm0yFot",
        "colab": {}
      },
      "source": [
        "nn_model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgltpwJnyFov",
        "colab": {}
      },
      "source": [
        "y_preds_nn = nn_model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zyehxpAeyFoy",
        "colab": {}
      },
      "source": [
        "f1 = f1_score(y_test, y_preds_nn, average=\"macro\")\n",
        "print (\"f1-score: \" + str(f1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iiWq77uQcZtl",
        "colab": {}
      },
      "source": [
        "nn_model.predict(X_test.iloc[0:5, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr87BMLX9BHg",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating Ensemble Learners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5sdzLiPyFok",
        "colab": {}
      },
      "source": [
        "models = {\n",
        "    \"Extreme Gradient Boost\": data_dir + \"/xgb_best.pkl\",\n",
        "    \"Gradient Boost\": data_dir + \"/gb_best.pkl\",\n",
        "    \"Ada Boost\": data_dir + \"/ada_best.pkl\",\n",
        "    \"Single Decision Tree\": data_dir + \"/dtc_best.pkl\"\n",
        "#     \"SVM\": data_dir + \"/svm_best.pkl\",\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWr0-GSrvzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model_name in models.keys():\n",
        "    model_file_name = models[model_name]\n",
        "    model = pickle.load(open(model_file_name, 'rb'))\n",
        "    y_preds = model.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_preds, average=\"macro\")\n",
        "    print (\"Model: \" + model_name + \" f1-score: \" + str(f1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O-RQjqboyFob"
      },
      "source": [
        "### Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ttOFDaSryFod",
        "colab": {}
      },
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "def print_top10(feature_names, clf, class_labels):\n",
        "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
        "    pp.pprint(sorted(list(zip(feature_names, clf.feature_importances_)), key=lambda x: x[1], \n",
        "reverse=True)[:20])\n",
        "\n",
        "for model_name in models.keys():\n",
        "    model_file_name = models[model_name]\n",
        "    model = pickle.load(open(model_file_name, 'rb'))\n",
        "    print(\"\\nModel: \" + model_name)\n",
        "    print(\"Best Params: \")\n",
        "    pp.pprint(model.get_params())\n",
        "    print(\"Top 10 Feature importances: \")\n",
        "    print_top10(X_train_sample.columns, model, model.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TcuK3o33yFo0"
      },
      "source": [
        "## Tuning the booking price of property"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z8JHJIIoY1bG"
      },
      "source": [
        "### Aim: Maximizing expected revneue from individual properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3xxUHQRyyFo1"
      },
      "source": [
        "Here I tune the booking price of the property by looking at the probability of the property being booked at given price. If the probability is too low, I try increasing it by setting the price the of that property slightly low and see if it increases the probability. My goal is to maximize the profit of the company by maximizing expected revneue from individual properties. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cw2mk1H8yFo1",
        "colab": {}
      },
      "source": [
        "Sequential.predict_proba = Sequential.predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUAoK8EPyFo3",
        "colab": {}
      },
      "source": [
        "import decimal\n",
        "\n",
        "def float_range(start, stop, step):\n",
        "    start = decimal.Decimal(start)\n",
        "    stop = decimal.Decimal(stop)\n",
        "    step = decimal.Decimal(step)\n",
        "    while (start < stop):\n",
        "        yield float(start)\n",
        "        start += step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PJyc81PlyFo4"
      },
      "source": [
        "As per the economic principle of price elasticity of demand, the quantity of a product demanded should be varying with changes in price like this curve if the demanded quantity is elastic to the price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y9UGvjevyFo4"
      },
      "source": [
        "![Price Elasticity of Demand Curve](http://wikieducator.org/images/0/0f/Ed1.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Um-wOQMpyFo5"
      },
      "source": [
        "In our case, the quantity of demand synonymous to the probability of the property being booked and the price is the booking price of the property. Let's try and check if some randomly selected properties from our dataset demonstrates price elasticity for probability of being booked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o33JjjeTyFo5"
      },
      "source": [
        "### Methods to calculate probability of a property being booked at given normalized price and market condition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd8TYlILEQhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_model = load_model(data_dir + \"/nn_best_model_cv.h5\")\n",
        "def calc_prob_booked_nn(row):\n",
        "  df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
        "  return 1 - nn_model.predict(df)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulKZakl5Ec7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_clf = pickle.load(open(data_dir + \"/xgb_best.pkl\", 'rb'))\n",
        "def calc_prob_booked_xgb(row):\n",
        "  df = pd.DataFrame(data=row.to_dict(), index=[0])  \n",
        "  return xgb_clf.predict_proba(df)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh37bojhIYn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gb_clf = pickle.load(open(data_dir + \"/gb_best.pkl\", 'rb'))\n",
        "def calc_prob_booked_gb(row):\n",
        "  df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
        "  return gb_clf.predict_proba(df)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMGvhTkGMpkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ada_clf = pickle.load(open(data_dir + \"/ada_best.pkl\", 'rb'))\n",
        "def calc_prob_booked_ada(row):\n",
        "  df = pd.DataFrame(data=row.to_dict(), index=[0])\n",
        "  return ada_clf.predict_proba(df)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQwZ5aLsITpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtc_clf = pickle.load(open(data_dir + \"/dtc_best.pkl\", 'rb'))\n",
        "def calc_prob_booked_dtc(row):\n",
        "  df = pd.DataFrame(data=row.to_dict(), index=[0])  \n",
        "  return dtc_clf.predict_proba(df)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTHWeAecuAR6",
        "colab_type": "text"
      },
      "source": [
        "### Price Elasticity for probability of a property getting booked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "idJ1N5k4yFo8",
        "colab": {}
      },
      "source": [
        "def draw_price_elasticity_curves(calc_prob_booked):\n",
        "  fig, ax = plt.subplots(3, 2, figsize=(15,10))\n",
        "  sample_listings = [listing for (index, listing) in X_test.sample(6, random_state=42).copy().iterrows()]\n",
        "\n",
        "  for plot_row in range(0,3):\n",
        "    for plot_col in range(0,2):  \n",
        "      listing = sample_listings.pop()\n",
        "      current_normalized_price = listing[\"price_calendar_normalized\"]\n",
        "      current_price = int(round(listing[\"price_calendar_normalized\"] * listing[\"total_env_prices\"],0))\n",
        "      price_upper = current_normalized_price * (1 + 100/100)\n",
        "      price_lower = current_normalized_price * 0\n",
        "      normalized_price_range = list(float_range(str(price_lower), str(price_upper), str((price_upper - price_lower)/50)))\n",
        "\n",
        "      probs = []\n",
        "      absolute_prices = [listing[\"total_env_prices\"] * normalized_price for normalized_price in normalized_price_range]\n",
        "\n",
        "      for price in normalized_price_range:\n",
        "          listing[\"price_calendar_normalized\"] = price\n",
        "          prob = calc_prob_booked(listing)\n",
        "          probs.append(prob)\n",
        "\n",
        "      price_elasticity_curve, = ax[plot_row, plot_col].plot(absolute_prices, probs)\n",
        "      ax[plot_row, plot_col].set_ylabel('Probability of property being booked')\n",
        "      ax[plot_row, plot_col].set_xlabel('Booking price of property')\n",
        "      current_price_line = ax[plot_row, plot_col].axvline(x=current_price, color='g')   \n",
        "\n",
        "      # Measuring price elasticity\n",
        "      elasticity = calculate_price_elasticity(calc_prob_booked, listing)\n",
        "\n",
        "      ax[plot_row, plot_col].legend((current_price_line, price_elasticity_curve), ('Current price = ' +str(current_price), 'Price elasticity ED = ' +str(round(elasticity, 5))))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cerGbSpImd4",
        "colab_type": "text"
      },
      "source": [
        "### Price elasticity for probability of booking learnt by Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsBY5ulTISHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_price_elasticity_curves(calc_prob_booked_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDex2VuiyFo-"
      },
      "source": [
        "As we can see above, choosing some random properties from dataset and plotting relationship between normalized price and probability of getting the property booked shows that they demonstrate price elasticity for probability of the property being booked.\n",
        "\n",
        "Although the price elasticity curve generated using Neural Network is smooth, it represents that probability of property getting booked is inelastic towards price in very large price range. Such model does not very well represent the real world scenario where demand of property can be inelastic to price within only a small range of price.\n",
        "\n",
        "In my first iteration of project, I tried using absolute price to evaluate the relationship between probability of property being booked and the price. At that time, I the plot did not follow the price elasticity curve.\n",
        "\n",
        "One of the assumption in the price elasticity curve is that all the other factors in the market should be held relatively constant and only the price of the property should be varying. Only then the relation between booking probability and price will follow the popular price elasticity curve in wide range of price variation.\n",
        "\n",
        "The absolute value of price may have been increased in the dataset when the overall demand of properties for booking have increased. In such case, the property might be still getting booked at higher price duing the periods of higher demand. Therefore based on the dataset, the model trained on absolute price will suggest that the probability of booking may also increase when the property price is increased. \n",
        "\n",
        "To tackle this issue, I implemented workaround by normalizing the price relative to the sum of booking prices of all the other 100 properties that we are using in our training dataset to represent the competitive market environment conditions. Now we can observe the trend of change in probability along with the change in relative price and see that it shows some price elasticity as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Ba6C_tJHvc",
        "colab_type": "text"
      },
      "source": [
        "### Price Elasticity for probability of booking learnt by Extreme Gradient Boosting (XGBoost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ooOBgcJN_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_price_elasticity_curves(calc_prob_booked_xgb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu9XrN2qI5iN",
        "colab_type": "text"
      },
      "source": [
        "### Price Elasticity for probability of booking learnt by Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxkOKsahINy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_price_elasticity_curves(calc_prob_booked_gb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bDqgrtO1NAV2"
      },
      "source": [
        "### Price Elasticity for probability of booking learnt by Ada Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0K77mYrRNAV6",
        "colab": {}
      },
      "source": [
        "draw_price_elasticity_curves(calc_prob_booked_ada)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsSSm4gKIw-9",
        "colab_type": "text"
      },
      "source": [
        "### Price elasticity for probability of booking learnt by Single Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL9OfEMlVA5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_price_elasticity_curves(clac_prob_booked_dtc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgkINGajl7T3",
        "colab_type": "text"
      },
      "source": [
        "### Calculating the expected revenue from properties after tuning the price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7OrVhYAmyv6",
        "colab_type": "text"
      },
      "source": [
        "Let's tune prices of the properties that show significant price elasticity for demand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiMbgm8duMnf",
        "colab_type": "text"
      },
      "source": [
        "`get_price_elasticity_curve` function gets price elasticity curve for the probability of property getting booked by calculating the probability from the given calc_prob_booked function within a range values varying from current normalized price of property by specified percentage. It then fits a polynomial curve that fits the points calculated from the probability of property getting booked at that normalized price point it returns that fitted curve as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahzt_W6TPQnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_price_elasticity_curve(listing, calc_prob_booked, percentage):\n",
        "  current_norm_price = listing[\"price_calendar_normalized\"]\n",
        "  higher_price_normalized = current_norm_price * (1 + (percentage/100))\n",
        "  lower_price_normalized = max(0, current_norm_price * (1 - (percentage/100)))    \n",
        "  samples_price_norm = list(float_range(str(lower_price_normalized), str(higher_price_normalized), str((higher_price_normalized - lower_price_normalized)/100)))\n",
        "  samples_price_norm += list(float_range(str(current_norm_price * (0.95)), str(current_norm_price * (1.05)), str(current_norm_price * (0.1/50))))\n",
        "\n",
        "  probs = []\n",
        "  \n",
        "  for sample_price_norm in samples_price_norm:\n",
        "    listing[\"price_calendar_normalized\"] = sample_price_norm\n",
        "    prob = calc_prob_booked(listing)\n",
        "    probs.append(prob)  \n",
        "\n",
        "  X = pd.DataFrame({\"x\" : samples_price_norm})\n",
        "  y = pd.DataFrame({\"y\": probs})\n",
        "  curve = make_pipeline(PolynomialFeatures(degree=1), LinearRegression())\n",
        "  curve.fit(X,y)\n",
        "  return curve\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y0TpiBcVTbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_price_elasticity_for_prop(listing, calc_prob_booked, percentage, curve, rec_price):\n",
        "    square_feet = listing[\"square_feet\"]\n",
        "    beds = listing[\"beds\"]\n",
        "    month = listing[\"month\"]\n",
        "    year = listing[\"year\"]\n",
        "    week_of_month = listing[\"week_of_month\"]\n",
        "    day_of_week = listing[\"day_of_week\"]\n",
        "    accommodates = listing[\"accommodates\"]\n",
        "    neighbourhood_cleansed = listing[\"neighbourhood_cleansed\"]\n",
        "    city = listing[\"city\"]\n",
        "    print (f\"Price elasticity plot for a property of\")\n",
        "    print (f\"Size: {square_feet}sq.ft\")\n",
        "    print (f\"Accommodates: {accommodates}\")\n",
        "    print (f\"Bedrooms: {bedrooms}\")\n",
        "    print (f\"Day: {day_of_week}\")\n",
        "    print (f\"Week of month: {week_of_month}\")\n",
        "    print (f\"Month: {month}\")\n",
        "    print (f\"Year: {year}\")\n",
        "    print (f\"Neighbourhood: {neighbourhood_cleansed}\")\n",
        "    \n",
        "    current_normalized_price = listing[\"price_calendar_normalized\"]\n",
        "    current_price = int(round(listing[\"price_calendar_normalized\"] * listing[\"total_env_prices\"],0))\n",
        "    price_upper = current_normalized_price * (1 + percentage/100)\n",
        "    price_lower = current_normalized_price * max(0, (1 - percentage/100))\n",
        "    normalized_price_range = list(float_range(str(price_lower), str(price_upper), str((price_upper - price_lower)/50)))\n",
        "\n",
        "    probs = []\n",
        "    absolute_prices = [listing[\"total_env_prices\"] * normalized_price for normalized_price in normalized_price_range]\n",
        "    curve_probs = []\n",
        "    for price in normalized_price_range:\n",
        "        listing[\"price_calendar_normalized\"] = price\n",
        "        prob = calc_prob_booked(listing)\n",
        "        probs.append(prob)       \n",
        "        df_norm_price = pd.DataFrame(data={\"x\" : price}, index=[0])\n",
        "        curve_prob = curve.predict(df_norm_price)[0]\n",
        "        curve_probs.append(curve_prob)\n",
        "   \n",
        "    price_elasticity_curve, = plt.plot(absolute_prices, probs)\n",
        "    regression_curve, = plt.plot(absolute_prices, curve_probs)\n",
        "    recommended_price_line, = plt.axvline(x=rec_price, color='g')\n",
        "    plt.ylabel('Probability of property being booked')\n",
        "    plt.xlabel('Booking price of property')\n",
        "    beds = listing[\"beds\"]\n",
        "    square_feet= listing[\"square_feet\"]\n",
        "    current_price_line = plt.axvline(x=current_price, color='r')   \n",
        "    plt.legend((current_price_line, \n",
        "                recommended_price_line,\n",
        "                price_elasticity_curve, \n",
        "                regression_curve), \n",
        "               ('Current price = ' +str(current_price), \n",
        "                'Recommended price = ' + str(rec_price),\n",
        "                'Booking probability at price', \n",
        "                'Fitted Regression line'))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAdtVEu0lxiV",
        "colab_type": "text"
      },
      "source": [
        "- For each property I first check whether the property follows conventional price elasticity where the probability of the property getting booked increases as its relative price is decreased and only tuned price for those properties that demonstrated such trend.\n",
        "- Instead of using exact probability predicted by the classifier, I decided to use the one derived from line fitted on the predicted probability values for normalized price range near the current normalized price, so that tuning algorithm has to work with smoothly varying values that smoothes sudden bumps in the probability values often seen to be generated by ensemble learners."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV85nECfSUEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_price_elasticity(curve, listing, percentage_to_check):\n",
        "  current_normalized_price = listing[\"price_calendar_normalized\"]\n",
        "  norm_price_1 = min(0, current_normalized_price * (1 - percentage_to_check/100))\n",
        "  price_1 = norm_price_1 * listing[\"total_env_prices\"]\n",
        "  listing[\"price_calendar_normalized\"] = norm_price_1\n",
        "  df_norm_price_1 = pd.DataFrame(data={\"x\" : norm_price_1}, index=[0])\n",
        "  d_1 = curve.predict(df_norm_price_1)[0]\n",
        "\n",
        "  norm_price_2 = current_normalized_price * (1 + percentage_to_check/100)\n",
        "  price_2 = norm_price_2 * listing[\"total_env_prices\"]\n",
        "  listing[\"price_calendar_normalized\"] = norm_price_2\n",
        "  df_norm_price_1 = pd.DataFrame(data={\"x\" : norm_price_1}, index=[0])\n",
        "  d_2 = curve.predict(df_norm_price_2)[0]\n",
        "\n",
        "  price_change = (price_2 - price_1)/((price_2 + price_1)/2)\n",
        "  demand_change = (d_2 - d_1)/((d_2 + d_1)/2)\n",
        "  elasticity = demand_change / -price_change\n",
        "  return elasticity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3j2N3B5_yFpT",
        "colab": {}
      },
      "source": [
        "def calc_revenue_at_tuned_price(row, calc_prob_booked):  \n",
        "    current_price_norm = row[\"price_calendar_normalized\"]\n",
        "    current_price = current_price_norm * row[\"total_env_prices\"]\n",
        "    prob_booked = calc_prob_booked(row)    \n",
        "#     print(\"price_calendar: \" + str(current_price))\n",
        "    \n",
        "\n",
        "    percentage_to_check = 20\n",
        "    \n",
        "    curve = get_price_elasticity_curve(listing=row, calc_prob_booked=calc_prob_booked, percentage=20)\n",
        "        \n",
        "    print (\"Checking for price elasticity...\")\n",
        "    row[\"price_calendar_normalized\"] = current_price_norm\n",
        "    if calculate_price_elasticity(curve, listing=row, percentage_to_check=percentage_to_check) > 0.1:          \n",
        "        print(\"✔ The property follows significant price elasiticity in reasonable price range according to model\")\n",
        "\n",
        "        print (\"Probability of being booked at current price: \" + str(prob_booked))\n",
        "        print (\"Probability of being booked at higher price: \" + str(prob_booked_higher_price))\n",
        "        print (\"Probability of being booked at lower price: \" + str(prob_booked_lower_price))\n",
        "        row[\"price_calendar_normalized\"] = current_price_norm\n",
        "        current_expected_revenue = current_price * prob_booked        \n",
        "        print (\"\")\n",
        "        print(\"Current price: \" + str(round(current_price, 0)))\n",
        "        print(\"Probability of being booked at current price: \" + str(prob_booked))\n",
        "        print(\"Expected revenue at current price: \" + str(current_expected_revenue))       \n",
        "        \n",
        "        max_expected_revenue = -math.inf\n",
        "        prob_at_max = None\n",
        "        price_at_max = None\n",
        "        for trial_price_norm in float_range(str(lower_price_normalized), str(higher_price_normalized), str((higher_price_normalized-lower_price_normalized)/100)):\n",
        "          # Instead of using probability predicted by the classifier,\n",
        "          # I decided to use the one derived from line fitted on the values\n",
        "          # in normalized price range near the current normalized price\n",
        "          # so that I can have a smoothly varying values which avoid sudden\n",
        "          # bumps in the probability values often seen to be generated by\n",
        "          # ensemble learners.\n",
        "#             row[\"price_calendar_normalized\"] = trial_price_norm\n",
        "#             prob_at_trial_price_norm = calc_prob_booked(row)\n",
        "            df_trial = pd.DataFrame(data={\"x\" : trial_price_norm}, index=[0])\n",
        "            prob_at_trial_price_norm = curve.predict(df_trial)[0]   \n",
        "            expected_revenue = prob_at_trial_price_norm * trial_price_norm * row[\"total_env_prices\"]\n",
        "            if expected_revenue > max_expected_revenue:\n",
        "                max_expected_revenue = expected_revenue\n",
        "                prob_at_max = prob_at_trial_price_norm\n",
        "                price_at_max = trial_price_norm * row[\"total_env_prices\"]\n",
        "        draw_price_elasticity_for_prop(row, calc_prob_booked, percentage_to_check, curve, rec_price=round(price_at_max,0))\n",
        "        print (\"Recommended price: \" + str(round(price_at_max,0)))\n",
        "        print (\"Probability of booked at recommended price: \" + str(np.round(prob_at_max, 5)))\n",
        "        print (\"Expected revenue at recommended price: \" + str(np.round(max_expected_revenue,2)))\n",
        "        print (\"Percentage of recommended price change: \" + str(np.round(100*(price_at_max - current_price)/current_price, 3)) +\"%\")\n",
        "        print (\"Percentage of change in expected revenue: \" + str(np.round(100*(max_expected_revenue - current_expected_revenue)/current_expected_revenue, 2)) +\"%\")\n",
        "        print (\"----------------------------------------------------------------\")\n",
        "        return max_expected_revenue\n",
        "    else:\n",
        "        print(\"✘ The property does not follow desired price elasiticity in reasonable price range according to model\")\n",
        "        return current_price * prob_booked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt7uWkaXk2lu",
        "colab_type": "text"
      },
      "source": [
        "I decided to tune the prices of properties using Extreme Gradient Boosting model for predicting probability of property being booked under giving time, price and market conditions. The reason is that it shows higher accuracy in terms of F1-score as compared to neural network model. Even though the predicted probability graph while varying normalized price is not as smooth as the one generated by neural network, the more accurate prediction of probabilities for property getting booked leads to more accurate prediction for expected revenue from properties at given price point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1NMeMG2S7Xk",
        "colab": {}
      },
      "source": [
        "expected_revenue_at_current_prices = 0\n",
        "expected_revenue_at_recommended_prices = 0\n",
        "number_of_properties_to_be_sampled = 1000\n",
        "number_of_properties_with_price_updated = 0\n",
        "\n",
        "for index, row in X_test.sample(n=number_of_properties_to_be_sampled, random_state=42).copy().iterrows():  \n",
        "    expected_revenue_at_current_prices += row[\"price_calendar_normalized\"] * row[\"total_env_prices\"] * calc_prob_booked_xgb(row)\n",
        "    expected_revenue_at_recommended_prices += calc_revenue_at_tuned_price(row, calc_prob_booked=calc_prob_booked_xgb)\n",
        "    if np.round(expected_revenue_at_current_prices, 2) != np.round(expected_revenue_at_recommended_prices, 2):\n",
        "      number_of_properties_with_price_updated += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX7w51MlNFok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "percentage_of_change = 100*(expected_revenue_at_recommended_prices - expected_revenue_at_current_prices)/expected_revenue_at_current_prices\n",
        "\n",
        "print(f\"After tuning prices for {number_of_properties_with_price_updated}\")\n",
        "print(f\"out of {number_of_properties_to_be_sampled} properties evaluated\")\n",
        "print(\"the percentage of change in expected revenue is: \" + str(np.round(percentage_of_change, 2)) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3USkXgnswjX",
        "colab_type": "text"
      },
      "source": [
        "### Ideas for improvement in accuracy of this predictive model\n",
        "- Accuracy of predicting the probability of the property getting booked can be further improved by using all the training data availabile for training the Extreme Gradient Boosting model. Currently I have used only 100,000 samples execute my code within memory constraints imposed by Google Colab environment.\n",
        "- Alternate models like deep neural network can also be utilized with availability of larger dataset and computing resources to train it and choosing the most optimal hyperparameters like number of hidden layers and number of neurons in each layer etc.\n",
        "\n",
        "This kind of improvements can result in more accurate prediction about the expected revenue from property at given price point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc8FY7eSmop1",
        "colab_type": "text"
      },
      "source": [
        "## Application of this price tuning model based on predictive analysis\n",
        "There might be a limitation for **Airbnb** based on its business policy where prices are largely set by property owners and there is a less room for Airbnb to experiment with difference price points of a property to gather sufficient data to understand price elasticity of each property for its demand.\n",
        "\n",
        "Booking companies like **Booking.com**, **Trivago** and **OYO** can benefit from such kind of predictive price tuning model because they have more control over the booking price of the hotel room. Such a company can easily look at its past data of having each room offered at different prices and estimating the price elasticity for demand for each hotel room of some type. It can then train a predictive model for estimating the probability of a property getting booked at given price point on given day and market scenario. After calculating the price elasticity for given property, it can then tune the price of the hotel room type using above suggested method such that it maximizes expected revenue from that hotel room type on given day."
      ]
    }
  ]
}